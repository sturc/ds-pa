{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Housing Classification SVM MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow as mlf\n",
    "import mlflow.sklearn\n",
    "import seaborn as sns\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "\n",
    "import pickle\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = \"../data/Boston_Housing_Data.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(inputFile,delimiter=\";\")\n",
    "print(df.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df.drop([\"MEDV\",\"CAT\"],axis=1) # drop label attribute from the features\n",
    "df_labels = df[[\"CAT\"]].copy()\n",
    "display(df_features)\n",
    "display(df_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train validate test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_features,df_labels,test_size=0.2,random_state=1234)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train,y_train,test_size=0.2,random_state=1234)\n",
    "display (X_train)\n",
    "display (X_test) \n",
    "display (X_validate)\n",
    "display (y_train)\n",
    "display (y_test)\n",
    "display (y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().set_output(transform='pandas').fit(X_train) # fit the scaler to the training data\n",
    "X_train = scaler.transform(X_train)\n",
    "X_validate = scaler.transform(X_validate)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model Build the train Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc = LinearSVC(C=0.5, dual='auto', loss='hinge', max_iter=8000)\n",
    "\n",
    "def train(sk_model, X, y):\n",
    "    \"\"\" Train a sklearn model and log the training accuracy to MLflow \"\"\"\n",
    "    sk_model = sk_model.fit(X, y)\n",
    "    train_acc = sk_model.score(X, y)\n",
    "    mlf.log_metric(\"train_acc\", train_acc)\n",
    "    print(f\"Train Accuracy: {train_acc:.3%}\")\n",
    "    return sk_model\n",
    "\n",
    "#lsvc_model = train(lsvc,X_train,y_train[\"CAT\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sk_model, X, y):\n",
    "    eval_acc = sk_model.score(X, y)\n",
    "    preds = sk_model.predict(X)\n",
    "    auc_score = accuracy_score(y, preds)\n",
    "    mlf.log_metric(\"eval_acc\", eval_acc)\n",
    "    mlf.log_metric(\"auc_score\", auc_score)\n",
    "    print(f\"Auc Score: {auc_score:.3%}\")\n",
    "    print(f\"Eval Accuracy: {eval_acc:.3%}\")   \n",
    "    conf_matrix = confusion_matrix(y_test, preds)\n",
    "    ax = sns.heatmap(conf_matrix, annot=True,fmt='g') \n",
    "    ax.invert_xaxis()\n",
    "    ax.invert_yaxis()\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.title(\"Confusion Matrix\") \n",
    "    plt.savefig(\"sklearn_conf_matrix.png\")\n",
    "    mlf.log_artifact(\"sklearn_conf_matrix.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run and log experiments and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"svm_model\"\n",
    "model_uid = None\n",
    "mlf.set_experiment(\"bosten_housing_svm_experiment\")\n",
    "with mlf.start_run():\n",
    "    lsvc_model= train(lsvc, X_train,y_train[\"CAT\"])\n",
    "    evaluate(lsvc_model, X_test, y_test[\"CAT\"])\n",
    "    inferred_signature = mlf.models.infer_signature(X_train, y_test)\n",
    "    mlf.sklearn.log_model(lsvc_model,name=model_name, signature=inferred_signature)\n",
    "    model_uid = mlf.active_run().info.run_id\n",
    "    print(\"Model run: \",model_uid )\n",
    "mlf.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the last model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = mlf.sklearn.load_model(\"runs:/\"+model_uid+\"/\"+model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print(\"Test Error = \" ,(1.0 - accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "b4f307b8e534e9e53f9c486642ecef6c8e0edf2f9b060856b2ce39a93f47f0e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
